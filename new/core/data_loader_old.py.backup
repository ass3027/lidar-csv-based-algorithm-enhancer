#!/usr/bin/env python3
"""데이터 로딩 모듈 - CSV loading module for queue logs"""

import csv
from pathlib import Path
from ..utils.outlier_detection import detect_outliers_iqr


def load_all_logs(log_dir="passing_log"):
    log_path = Path(log_dir)
    all_data = []

    if not log_path.exists():
        print(f"경고: 디렉토리 '{log_dir}'를 찾을 수 없습니다.")
        return all_data

    csv_files = sorted(log_path.glob("passingObject_*.csv"))

    if not csv_files:
        print(f"경고: '{log_dir}' 디렉토리에 CSV 파일이 없습니다.")
        return all_data

    for csv_file in csv_files:
        print(f"로딩중: {csv_file.name}...")
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    parsed_row = {
                        'timestamp': row['timestamp'],
                        'date': csv_file.stem.replace('passingObject_', ''),
                        'zone_id': int(row['zone_id']),
                        'objectCount': int(row['objectCount']),
                        'lidarEstTime': float(row['lidarEstTime']),
                        'throughputEstTime': float(row['throughputEstTime']),
                        'finalEstTime': float(row['finalEstTime']),
                        'actualPassTime': int(row['actualPassTime'])
                    }
                    all_data.append(parsed_row)
                except (ValueError, KeyError):
                    continue

    return all_data


def filter_outliers(data):
    print("\n이상치 탐지 중...")

    error_extractors = {
        'actual_time': lambda r: r['actualPassTime'],
        'lidar_error': lambda r: r['lidarEstTime'] - r['actualPassTime'],
        'throughput_error': lambda r: r['throughputEstTime'] - r['actualPassTime'],
        'final_error': lambda r: r['finalEstTime'] - r['actualPassTime']
    }

    outlier_sets = {
        name: detect_outliers_iqr([extractor(row) for row in data])
        for name, extractor in error_extractors.items()
    }

    all_outlier_indices = set().union(*outlier_sets.values())

    filtered_data = [
        row for i, row in enumerate(data)
        if i not in all_outlier_indices
    ]

    total_count = len(data)
    removed_count = len(all_outlier_indices)
    removal_rate = (removed_count / total_count) * 100

    outlier_stats = {
        'total_records': total_count,
        'removed_records': removed_count,
        'filtered_records': len(filtered_data),
        'removal_rate_pct': removal_rate,
        'outliers_by_type': {name: len(indices) for name, indices in outlier_sets.items()}
    }

    print(f"  총 레코드: {total_count:,} 건")
    print(f"  제거된 레코드: {removed_count:,} 건 ({removal_rate:.1f}%)")
    print(f"  필터링 후: {len(filtered_data):,} 건")

    return filtered_data, outlier_stats
